{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetParser():\n",
    "    def __init__(self, root_dir, images_dir, labels_csv):\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(root_dir, images_dir,\"*.png\")))\n",
    "        self.labels_df = self._labels_by_task(root_dir=root_dir, labels_csv=labels_csv)\n",
    "        \n",
    "        self.labels = ['Cardiomegaly','Emphysema','Effusion',\n",
    "                           'Hernia','Nodule','Pneumothorax','Atelectasis',\n",
    "                           'Pleural_Thickening','Mass','Edema','Consolidation',\n",
    "                           'Infiltration','Fibrosis','Pneumonia', 'No Finding']\n",
    "    \n",
    "    def visualize_random_images(self, num_images=1, label=None, display_label=False):\n",
    "        fig = plt.figure(figsize=(20,20))\n",
    "        fig.tight_layout(pad=10.0)\n",
    "        if label is None:\n",
    "            idxs = random.sample(range(len(self.image_paths)), num_images)\n",
    "        else:\n",
    "            idxs = [idx for idx in range(len(self.labels_df['Label'])) if label in self.labels_df['Label'][idx]]\n",
    "            if len(idxs) < num_images:\n",
    "                num_images = len(idxs)\n",
    "            else:\n",
    "                idxs = random\n",
    "                (idxs, num_images)\n",
    "                \n",
    "        num_rows = math.ceil(np.sqrt(num_images))\n",
    "        num_cols = math.ceil(num_images/num_rows)\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            img = cv2.imread(self.image_paths[idxs[i]])\n",
    "            plt.subplot(num_rows, num_cols, i+1)\n",
    "            if display_label:\n",
    "                plt.gca().set_title(self.labels_df['Label'][idxs[i]],wrap=True)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    def _labels_by_task(self, root_dir=None, labels_csv=None):\n",
    "\n",
    "        labels_df = pd.read_csv(os.path.join(root_dir, labels_csv))\n",
    "        image_path = {os.path.basename(x): x for x in glob.glob(os.path.join(root_dir, 'images', '*.png'))}\n",
    "        \n",
    "        labels_df = labels_df[labels_df['Image Index'].map(os.path.basename).isin(image_path)]\n",
    "\n",
    "        new_labels_df = pd.DataFrame()\n",
    "        new_labels_df['Id'] = labels_df['Image Index'].copy()\n",
    "        \n",
    "        new_labels_df['Label'] = labels_df['Finding Labels'].apply(lambda val: val.split('|'))\n",
    "        \n",
    "        del labels_df\n",
    "        \n",
    "        return new_labels_df\n",
    "        \n",
    "    def get_labels_df(self):\n",
    "        new_labels_df = self.labels_df.copy()\n",
    "        \n",
    "        for i in range(len(new_labels_df)):\n",
    "                one_hot = [0 for element in self.labels]\n",
    "                for element in new_labels_df['Label'][i]:\n",
    "                    one_hot[self.labels.index(element)] = 1\n",
    "                new_labels_df['Label'][i] = one_hot\n",
    "                \n",
    "        return new_labels_df\n",
    "    \n",
    "    def sample(self, num_samples, is_weighted=False):\n",
    "        if not is_weighted:\n",
    "            return self.labels_df.sample(num_samples)\n",
    "        else:\n",
    "            sample_weights = self.labels_df['Label'].map(lambda x: len(x)).values + 4e-2\n",
    "            sample_weights /= sample_weights.sum()\n",
    "            return self.labels_df.sample(num_samples, weights=sample_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Data:  5606\n"
     ]
    }
   ],
   "source": [
    "parser = DatasetParser(root_dir=\"/Users/ananyajain/Desktop/CSC413/CSC413-Final-Project/archive/sample\",\n",
    "                       images_dir=\"sample/images\",\n",
    "                       labels_csv=\"sample_labels.csv\")\n",
    "print(\"Total Trainable Data: \", parser.labels_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>00026524_002.png</td>\n",
       "      <td>[No Finding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>00006352_000.png</td>\n",
       "      <td>[No Finding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5173</th>\n",
       "      <td>00027630_001.png</td>\n",
       "      <td>[No Finding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>00009717_001.png</td>\n",
       "      <td>[No Finding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>00003867_010.png</td>\n",
       "      <td>[Atelectasis, Consolidation, Effusion]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id                                   Label\n",
       "5012  00026524_002.png                            [No Finding]\n",
       "1205  00006352_000.png                            [No Finding]\n",
       "5173  00027630_001.png                            [No Finding]\n",
       "1841  00009717_001.png                            [No Finding]\n",
       "735   00003867_010.png  [Atelectasis, Consolidation, Effusion]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = parser.sample(100, is_weighted=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  60\n",
      "Validation set size:  20\n",
      "Test set size:  20\n"
     ]
    }
   ],
   "source": [
    "train_val, test = train_test_split(df, test_size=0.2, random_state=42)  # Split into train+val (80%) and test (20%)\n",
    "train, val = train_test_split(train_val, test_size=0.25, random_state=42)  # Split remaining data into train (60%) and val (20%)\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "print(\"Training set size: \", len(train))\n",
    "print(\"Validation set size: \", len(val))\n",
    "print(\"Test set size: \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 validated image filenames belonging to 15 classes.\n",
      "Found 13 validated image filenames belonging to 15 classes.\n",
      "Found 12 validated image filenames belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip = True, \n",
    "                                   vertical_flip = False, \n",
    "                                   height_shift_range= 0.05, \n",
    "                                   width_shift_range=0.1, \n",
    "                                   rotation_range=5, \n",
    "                                   shear_range = 0.1,\n",
    "                                   fill_mode = 'reflect',\n",
    "                                   zoom_range=0.15)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)    \n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train,\n",
    "        directory='/Users/ananyajain/Desktop/CSC413/CSC413-Final-Project/archive/sample/sample/images',\n",
    "        x_col=\"Id\",\n",
    "        y_col=\"Label\",\n",
    "        batch_size=32,\n",
    "        target_size=(224,224),\n",
    "        classes = parser.labels)\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val,\n",
    "        directory='/Users/ananyajain/Desktop/CSC413/CSC413-Final-Project/archive/sample/sample/images',\n",
    "        x_col=\"Id\",\n",
    "        y_col=\"Label\",\n",
    "        batch_size=32,\n",
    "        target_size=(224,224),\n",
    "        classes = parser.labels)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test,\n",
    "    directory='/Users/ananyajain/Desktop/CSC413/CSC413-Final-Project/archive/sample/sample/images',\n",
    "    x_col=\"Id\",\n",
    "    y_col=\"Label\",\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    classes = parser.labels,\n",
    "    shuffle = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
